{"cells":[{"cell_type":"markdown","source":["Microsoft Fabric, Lakehouse Schemas refer to the logical organization of tables and views within a Lakehouse. A Lakehouse in Fabric is a unified data architecture that combines the best aspects of a data lake and a data warehouse, and schemas are used to logically group and manage datasets inside it."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a3ff97ae-3835-4324-b664-7ff1bcd89028"},{"cell_type":"markdown","source":["Let me break it down step by step:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4b7b55bb-073c-48f7-82d5-7e11993fba29"},{"cell_type":"markdown","source":["### 1. What is a Lakehouse in Fabric?\n","\n","A Lakehouse in Microsoft Fabric is a storage and analytics layer that:\n","\n","Stores structured, semi-structured, and unstructured data in OneLake (Fabric’s data lake).\n","\n","Supports Delta tables for ACID transactions.\n","\n","Allows you to query data using SQL, Spark, or Python.\n","\n","Can integrate seamlessly with Power BI, Dataflows, and Pipelines."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b6e1bd88-e7dc-4474-8f93-16241b8b4f09"},{"cell_type":"markdown","source":["### 2. What Are Lakehouse Schemas?\n","\n","In a Lakehouse, a schema is like a folder or namespace inside the Lakehouse that organizes tables and views.\n","\n","A schema helps group related tables logically.\n","\n","Similar to how schemas work in SQL databases.\n","\n","They make it easier to manage access permissions, governance, and organization.\n","\n","SalesLakehouse\n","\n","   ├── Schema: Sales\n","   \n","   │      ├── Table: Orders\n","\n","   │      ├── Table: Customers\n","\n","   │      └── View: Top10Orders\n","\n","   ├── Schema: Finance\n","\n","   │      ├── Table: Invoices\n","\n","   │      ├── Table: Payments\n","\n","   │      └── View: RevenueSummary\n","\n","   └── Schema: HR\n","   \n","          ├── Table: Employees\n","\n","          ├── Table: Salaries\n","\n","Here, Sales, Finance, and HR are separate schemas, making data organization clean and manageable.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f3456611-0335-43da-a450-c2aa0557b211"},{"cell_type":"markdown","source":["### 3. Purpose of Lakehouse Schemas\n","\n","| **Purpose**              | **Description**                                                                        |\n","| ------------------------ | -------------------------------------------------------------------------------------- |\n","| **Logical Organization** | Group related tables/views for better structure.                                       |\n","| **Data Governance**      | Apply schema-level permissions and policies.                                           |\n","| **Security**             | Restrict access to sensitive datasets by schema.                                       |\n","| **Simplified Queries**   | Use schema-qualified names to avoid conflicts: `Finance.Invoices` vs `Sales.Invoices`. |\n","| **Collaboration**        | Different teams can manage data independently in their own schemas.                    |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8c51babe-4a6c-4a10-9e80-e54f036bd814"},{"cell_type":"markdown","source":["### 4. How Lakehouse Schemas Work in Fabric\n","\n","Default Schema: Every Lakehouse comes with a default schema (usually dbo).\n","\n","Custom Schemas: You can create custom schemas for specific business domains.\n","\n","SQL Access: Schemas can be queried via the SQL endpoint of the Lakehouse.\n","\n","Delta Format: All tables, regardless of schema, are stored in Delta format under the hood.\n","\n","Integration with OneLake: Even though data is organized by schemas logically, it’s physically stored in OneLake."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"187b1410-9d26-42e2-a0c6-7c21795c3d3f"},{"cell_type":"markdown","source":["### 5. How to Use Schemas in Fabric\n","a) Create a Schema\n","\n","    CREATE SCHEMA Finance;\n","    CREATE SCHEMA HR;\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ce7d4c7f-6db8-4613-ae33-aa54b5a288f4"},{"cell_type":"markdown","source":["b) Create a Table in a Schema\n","\n","    CREATE TABLE Finance.Invoices (\n","    InvoiceID INT,\n","    CustomerID INT,\n","    Amount DECIMAL(10,2),\n","    InvoiceDate DATE\n",");\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1ed6ab03-7794-407e-a43b-f4feda8f68cd"},{"cell_type":"markdown","source":["c) Querying a Table\n","\n","    SELECT * FROM Finance.Invoices;\n","\n","\n","    "],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9c6ed7df-e229-42a8-8c95-8de1843b4b91"},{"cell_type":"markdown","source":["d) Managing Permissions\n","\n","    GRANT SELECT ON SCHEMA::Finance TO FinanceTeam;\n","    DENY SELECT ON SCHEMA::HR TO ExternalUsers;\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9d699fd7-0ef3-4acc-824a-461dd2c24971"},{"cell_type":"markdown","source":["### 6. Key Differences Between Schemas in Fabric Lakehouse vs Traditional SQL\n","| **Aspect**         | **Fabric Lakehouse**                     | **Traditional SQL DB**             |\n","| ------------------ | ---------------------------------------- | ---------------------------------- |\n","| **Storage**        | Backed by **OneLake** + **Delta**        | Stored in DB files                 |\n","| **Scalability**    | Optimized for **big data** analytics     | Limited to DB engine capacity      |\n","| **Access**         | SQL, Spark, Python, Dataflows            | Mostly SQL                         |\n","| **Integration**    | Native with **Power BI**, **Pipelines**  | Needs ETL tools                    |\n","| **Schema Purpose** | Logical grouping of **lakehouse tables** | Logical grouping of **DB objects** |\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2d61fb1e-4675-48cb-8122-b1f706a8360a"},{"cell_type":"markdown","source":["### 7. When to Use Multiple Schemas\n","\n","If you have different departments managing data → e.g., Sales, Finance, HR.\n","\n","If you need different security policies → restrict access by schema.\n","\n","If you want clear separation between raw, processed, and curated data.\n","\n","Example Structure for Data Zones:\n","\n","Lakehouse: EnterpriseData\n","\n","   ├── Schema: Raw\n","\n","   ├── Schema: Staging\n","   \n","   ├── Schema: Curated\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6785891d-afe7-4905-bd42-6e20c5c70ce5"},{"cell_type":"markdown","source":["### Summary\n","\n","Lakehouse Schemas in Microsoft Fabric are logical namespaces inside a Lakehouse.\n","\n","They organize tables and views, control access, and improve collaboration.\n","\n","They work similarly to SQL schemas but are optimized for big data and Delta tables.\n","\n","Perfect for structuring data for departments, data zones, and governance."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0f2fe4bd-d849-47ed-aff3-218027351da9"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}